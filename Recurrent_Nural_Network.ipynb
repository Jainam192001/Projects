{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2 Genrate Text using RNN"
      ],
      "metadata": {
        "id": "lHnq_8S7ma71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some useful librariers and dataset from local drive"
      ],
      "metadata": {
        "id": "7g4eoFX-myft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md8a_NhkaH7W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import RNN, SimpleRNNCell, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "with open(\"/content/drive/MyDrive/myfile.txt\") as myfile:\n",
        "    mytext = myfile.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After import the text data...reviewing it with mytext statement"
      ],
      "metadata": {
        "id": "LOHCLw7nOAZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mytext\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "qoKr98Qyagmg",
        "outputId": "989186b3-2a35-4ebf-aba7-ad91d84c49ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Uttarakhand Police said Saturday that they had arrested Abdul Malik who allegedly led the violent protests in Haldwani on February 8 in which four persons were killed.\\n\\nSpeaking to The Indian Express, Inspector General and Police Headquarters spokesperson Nilesh Anand Bharne said Malik was arrested by Uttarakhand Police from New Delhi. His was the 79th arrest in the case.\\n\\nViolence erupted in Nainital district’s Haldwani on February 8 after the administration conducted a drive during which a mosque and a madrasa were demolished in Banbhoolpura area. District authorities said both structures stood on Nazool land — government land not officially mentioned in revenue records. As stones were pelted, cars torched and the local police station surrounded by a mob, Chief Minister Pushkar Singh Dhami had called for shoot-at-sight orders\\nHe said that on Saturday morning, they moved the First Additional District Judge (ADJ) court in Haldwani for anticipatory bail, but now, with Malik’s arrest, they will approach a lower court for regular bail.\\n\\nThree FIRs were registered in connection with the violence – one for the attack on the police station, another for the violence during the anti-encroachment drive, and the third for vandalising parked vehicles. They were registered under several Indian Penal Code sections, including 147 (rioting), 148 (rioting armed with deadly weapon), 307 (attempt to murder), and 332 (voluntarily causing hurt to public servant), as well as under the Prevention of Damage to Public Property Act.\\nMalik’s lawyer Ajay Kumar Bahuguna said they were moving a bail application. He said though police consider Malik the main instigator, he was not in Haldwani when the incident happened.\\n\\n“Malik was in Dehradun on February 8 (the day of the violence) for some personal work, and in Faridabad the previous day,” Bahuguna said.\\nNainital Senior Superintendent of Police Prahlad Narayan Meena had earlier said that the “illegal construction” was done by Malik. He also alleged that Malik had led the protests against the demolition.\\n\\nMalik’s wife, Safia, in a writ petition to the Uttarakhand High Court recently, presented the history of the property. According to her, it was originally leased by the British government in 1937, and following various transactions over the years, it became her inheritance upon the death of her father in 2013.\\n\\nShe said that despite a 2007 court order directing the consideration of freehold rights for the property, the process was stalled due to complications that arose with the Nazool Department.\\n\\nMeanwhile, the district administration has attached the property, and the Haldwani Municipal Corporation has served a notice to Malik, directing him to deposit Rs 2.44 crore to cover damage caused to government property during the February 8 violence.\\nPolice have also registered an FIR against Malik, his wife Safia, and four others for allegedly carrying out illegal plotting, illegal construction, and illegal transfer of land by using the name of a deceased person.\\n\\nFour days after the violence, Chief Minister Dhami announced that a police station would be built at the spot where the structures were demolished. And two days later, a temporary police outpost came up at the site.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform tokenization on given data set"
      ],
      "metadata": {
        "id": "Uwn18r9InDLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mytokenizer = Tokenizer()\n",
        "mytokenizer.fit_on_texts([mytext])\n",
        "total_words = len(mytokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "WUqn6OQzamN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mytokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe6VVdybatse",
        "outputId": "ab92b500-5c3a-4b76-9b93-68741b992752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'in': 2,\n",
              " 'a': 3,\n",
              " 'to': 4,\n",
              " 'and': 5,\n",
              " 'police': 6,\n",
              " 'said': 7,\n",
              " 'for': 8,\n",
              " 'of': 9,\n",
              " 'that': 10,\n",
              " 'malik': 11,\n",
              " 'were': 12,\n",
              " 'was': 13,\n",
              " 'on': 14,\n",
              " 'violence': 15,\n",
              " 'they': 16,\n",
              " 'haldwani': 17,\n",
              " 'by': 18,\n",
              " 'property': 19,\n",
              " 'had': 20,\n",
              " 'february': 21,\n",
              " '8': 22,\n",
              " 'he': 23,\n",
              " 'court': 24,\n",
              " 'with': 25,\n",
              " 'uttarakhand': 26,\n",
              " 'four': 27,\n",
              " 'during': 28,\n",
              " 'district': 29,\n",
              " 'land': 30,\n",
              " 'government': 31,\n",
              " 'as': 32,\n",
              " 'station': 33,\n",
              " 'at': 34,\n",
              " 'bail': 35,\n",
              " 'malik’s': 36,\n",
              " 'registered': 37,\n",
              " 'her': 38,\n",
              " 'illegal': 39,\n",
              " 'saturday': 40,\n",
              " 'arrested': 41,\n",
              " 'allegedly': 42,\n",
              " 'led': 43,\n",
              " 'protests': 44,\n",
              " 'which': 45,\n",
              " 'indian': 46,\n",
              " 'his': 47,\n",
              " 'arrest': 48,\n",
              " 'nainital': 49,\n",
              " 'after': 50,\n",
              " 'administration': 51,\n",
              " 'drive': 52,\n",
              " 'demolished': 53,\n",
              " 'structures': 54,\n",
              " 'nazool': 55,\n",
              " 'not': 56,\n",
              " 'chief': 57,\n",
              " 'minister': 58,\n",
              " 'dhami': 59,\n",
              " 'under': 60,\n",
              " 'rioting': 61,\n",
              " 'public': 62,\n",
              " 'damage': 63,\n",
              " 'bahuguna': 64,\n",
              " 'day': 65,\n",
              " 'also': 66,\n",
              " 'against': 67,\n",
              " 'wife': 68,\n",
              " 'safia': 69,\n",
              " 'it': 70,\n",
              " 'directing': 71,\n",
              " 'has': 72,\n",
              " 'days': 73,\n",
              " 'abdul': 74,\n",
              " 'who': 75,\n",
              " 'violent': 76,\n",
              " 'persons': 77,\n",
              " 'killed': 78,\n",
              " 'speaking': 79,\n",
              " 'express': 80,\n",
              " 'inspector': 81,\n",
              " 'general': 82,\n",
              " 'headquarters': 83,\n",
              " 'spokesperson': 84,\n",
              " 'nilesh': 85,\n",
              " 'anand': 86,\n",
              " 'bharne': 87,\n",
              " 'from': 88,\n",
              " 'new': 89,\n",
              " 'delhi': 90,\n",
              " '79th': 91,\n",
              " 'case': 92,\n",
              " 'erupted': 93,\n",
              " 'district’s': 94,\n",
              " 'conducted': 95,\n",
              " 'mosque': 96,\n",
              " 'madrasa': 97,\n",
              " 'banbhoolpura': 98,\n",
              " 'area': 99,\n",
              " 'authorities': 100,\n",
              " 'both': 101,\n",
              " 'stood': 102,\n",
              " '—': 103,\n",
              " 'officially': 104,\n",
              " 'mentioned': 105,\n",
              " 'revenue': 106,\n",
              " 'records': 107,\n",
              " 'stones': 108,\n",
              " 'pelted': 109,\n",
              " 'cars': 110,\n",
              " 'torched': 111,\n",
              " 'local': 112,\n",
              " 'surrounded': 113,\n",
              " 'mob': 114,\n",
              " 'pushkar': 115,\n",
              " 'singh': 116,\n",
              " 'called': 117,\n",
              " 'shoot': 118,\n",
              " 'sight': 119,\n",
              " 'orders': 120,\n",
              " 'morning': 121,\n",
              " 'moved': 122,\n",
              " 'first': 123,\n",
              " 'additional': 124,\n",
              " 'judge': 125,\n",
              " 'adj': 126,\n",
              " 'anticipatory': 127,\n",
              " 'but': 128,\n",
              " 'now': 129,\n",
              " 'will': 130,\n",
              " 'approach': 131,\n",
              " 'lower': 132,\n",
              " 'regular': 133,\n",
              " 'three': 134,\n",
              " 'firs': 135,\n",
              " 'connection': 136,\n",
              " '–': 137,\n",
              " 'one': 138,\n",
              " 'attack': 139,\n",
              " 'another': 140,\n",
              " 'anti': 141,\n",
              " 'encroachment': 142,\n",
              " 'third': 143,\n",
              " 'vandalising': 144,\n",
              " 'parked': 145,\n",
              " 'vehicles': 146,\n",
              " 'several': 147,\n",
              " 'penal': 148,\n",
              " 'code': 149,\n",
              " 'sections': 150,\n",
              " 'including': 151,\n",
              " '147': 152,\n",
              " '148': 153,\n",
              " 'armed': 154,\n",
              " 'deadly': 155,\n",
              " 'weapon': 156,\n",
              " '307': 157,\n",
              " 'attempt': 158,\n",
              " 'murder': 159,\n",
              " '332': 160,\n",
              " 'voluntarily': 161,\n",
              " 'causing': 162,\n",
              " 'hurt': 163,\n",
              " 'servant': 164,\n",
              " 'well': 165,\n",
              " 'prevention': 166,\n",
              " 'act': 167,\n",
              " 'lawyer': 168,\n",
              " 'ajay': 169,\n",
              " 'kumar': 170,\n",
              " 'moving': 171,\n",
              " 'application': 172,\n",
              " 'though': 173,\n",
              " 'consider': 174,\n",
              " 'main': 175,\n",
              " 'instigator': 176,\n",
              " 'when': 177,\n",
              " 'incident': 178,\n",
              " 'happened': 179,\n",
              " '“malik': 180,\n",
              " 'dehradun': 181,\n",
              " 'some': 182,\n",
              " 'personal': 183,\n",
              " 'work': 184,\n",
              " 'faridabad': 185,\n",
              " 'previous': 186,\n",
              " '”': 187,\n",
              " 'senior': 188,\n",
              " 'superintendent': 189,\n",
              " 'prahlad': 190,\n",
              " 'narayan': 191,\n",
              " 'meena': 192,\n",
              " 'earlier': 193,\n",
              " '“illegal': 194,\n",
              " 'construction”': 195,\n",
              " 'done': 196,\n",
              " 'alleged': 197,\n",
              " 'demolition': 198,\n",
              " 'writ': 199,\n",
              " 'petition': 200,\n",
              " 'high': 201,\n",
              " 'recently': 202,\n",
              " 'presented': 203,\n",
              " 'history': 204,\n",
              " 'according': 205,\n",
              " 'originally': 206,\n",
              " 'leased': 207,\n",
              " 'british': 208,\n",
              " '1937': 209,\n",
              " 'following': 210,\n",
              " 'various': 211,\n",
              " 'transactions': 212,\n",
              " 'over': 213,\n",
              " 'years': 214,\n",
              " 'became': 215,\n",
              " 'inheritance': 216,\n",
              " 'upon': 217,\n",
              " 'death': 218,\n",
              " 'father': 219,\n",
              " '2013': 220,\n",
              " 'she': 221,\n",
              " 'despite': 222,\n",
              " '2007': 223,\n",
              " 'order': 224,\n",
              " 'consideration': 225,\n",
              " 'freehold': 226,\n",
              " 'rights': 227,\n",
              " 'process': 228,\n",
              " 'stalled': 229,\n",
              " 'due': 230,\n",
              " 'complications': 231,\n",
              " 'arose': 232,\n",
              " 'department': 233,\n",
              " 'meanwhile': 234,\n",
              " 'attached': 235,\n",
              " 'municipal': 236,\n",
              " 'corporation': 237,\n",
              " 'served': 238,\n",
              " 'notice': 239,\n",
              " 'him': 240,\n",
              " 'deposit': 241,\n",
              " 'rs': 242,\n",
              " '2': 243,\n",
              " '44': 244,\n",
              " 'crore': 245,\n",
              " 'cover': 246,\n",
              " 'caused': 247,\n",
              " 'have': 248,\n",
              " 'an': 249,\n",
              " 'fir': 250,\n",
              " 'others': 251,\n",
              " 'carrying': 252,\n",
              " 'out': 253,\n",
              " 'plotting': 254,\n",
              " 'construction': 255,\n",
              " 'transfer': 256,\n",
              " 'using': 257,\n",
              " 'name': 258,\n",
              " 'deceased': 259,\n",
              " 'person': 260,\n",
              " 'announced': 261,\n",
              " 'would': 262,\n",
              " 'be': 263,\n",
              " 'built': 264,\n",
              " 'spot': 265,\n",
              " 'where': 266,\n",
              " 'two': 267,\n",
              " 'later': 268,\n",
              " 'temporary': 269,\n",
              " 'outpost': 270,\n",
              " 'came': 271,\n",
              " 'up': 272,\n",
              " 'site': 273}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we can pre process the data"
      ],
      "metadata": {
        "id": "RLCuZuwFT844"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_input_sequences = []\n",
        "for line in mytext.split('\\n'):\n",
        "    token_list = mytokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        my_n_gram_sequence = token_list[:i+1]\n",
        "        #print(my_n_gram_sequence)\n",
        "        my_input_sequences.append(my_n_gram_sequence)\n",
        "        #print(input_sequences)"
      ],
      "metadata": {
        "id": "29C2mtyEauO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(seq) for seq in my_input_sequences])\n",
        "input_sequences = np.array(pad_sequences(my_input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "metadata": {
        "id": "J8AE4LcAbGhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ham3e_JIbLIb",
        "outputId": "3dd0528c-3e68-47e2-881f-74ad6349dd1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 26,  6,  7,\n",
              "       40, 10, 16, 20, 41, 74, 11, 75], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = input_sequences[:, :-3]\n",
        "y = input_sequences[:, -3]"
      ],
      "metadata": {
        "id": "w075G3cebRm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-12vfvscAl3",
        "outputId": "99c13480-22fd-4880-f612-5dbba35f47d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  1, 26,  6], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZs2rc5IcEkX",
        "outputId": "e8ee4c5d-70ae-4f7b-a1ad-09e6c2ba87bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,  26,   6,   7,  40,  10,  16,  20,  41,  74,  11,  75,\n",
              "        42,  43,   1,  76,  44,   2,  17,  14,  21,  22,   2,  45,  27,\n",
              "        77,   0,  79,   4,   1,  46,  80,  81,  82,   5,   6,  83,  84,\n",
              "        85,  86,  87,   7,  11,  13,  41,  18,  26,   6,  88,  89,  90,\n",
              "        47,  13,   1,  91,  48,   2,   0,  15,  93,   2,  49,  94,  17,\n",
              "        14,  21,  22,  50,   1,  51,  95,   3,  52,  28,  45,   3,  96,\n",
              "         5,   3,  97,  12,  53,   2,  98,  99,  29, 100,   7, 101,  54,\n",
              "       102,  14,  55,  30, 103,  31,  30,  56, 104, 105,   2, 106, 107,\n",
              "        32, 108,  12, 109, 110, 111,   5,   1, 112,   6,  33, 113,  18,\n",
              "         3, 114,  57,  58, 115, 116,  59,  20, 117,   8, 118,  34,   0,\n",
              "        23,   7,  10,  14,  40, 121,  16, 122,   1, 123, 124,  29, 125,\n",
              "       126,  24,   2,  17,   8, 127,  35, 128, 129,  25,  36,  48,  16,\n",
              "       130, 131,   3, 132,  24,   8,   0, 134, 135,  12,  37,   2, 136,\n",
              "        25,   1,  15, 137, 138,   8,   1, 139,  14,   1,   6,  33, 140,\n",
              "         8,   1,  15,  28,   1, 141, 142,  52,   5,   1, 143,   8, 144,\n",
              "       145, 146,  16,  12,  37,  60, 147,  46, 148, 149, 150, 151, 152,\n",
              "        61, 153,  61, 154,  25, 155, 156, 157, 158,   4, 159,   5, 160,\n",
              "       161, 162, 163,   4,  62, 164,  32, 165,  32,  60,   1, 166,   9,\n",
              "        63,   4,  62,   0,  36, 168, 169, 170,  64,   7,  16,  12, 171,\n",
              "         3,  35, 172,  23,   7, 173,   6, 174,  11,   1, 175, 176,  23,\n",
              "        13,  56,   2,  17, 177,   1,   0, 180,  13,   2, 181,  14,  21,\n",
              "        22,   1,  65,   9,   1,  15,   8, 182, 183, 184,   5,   2, 185,\n",
              "         1, 186,  65, 187,   0,  49, 188, 189,   9,   6, 190, 191, 192,\n",
              "        20, 193,   7,  10,   1, 194, 195,  13, 196,  18,  11,  23,  66,\n",
              "       197,  10,  11,  20,  43,   1,  44,  67,   0,  36,  68,  69,   2,\n",
              "         3, 199, 200,   4,   1,  26, 201,  24, 202, 203,   1, 204,   9,\n",
              "         1,  19, 205,   4,  38,  70,  13, 206, 207,  18,   1, 208,  31,\n",
              "         2, 209,   5, 210, 211, 212, 213,   1, 214,  70, 215,  38, 216,\n",
              "       217,   1, 218,   9,  38, 219,   0, 221,   7,  10, 222,   3, 223,\n",
              "        24, 224,  71,   1, 225,   9, 226, 227,   8,   1,  19,   1, 228,\n",
              "        13, 229, 230,   4, 231,  10, 232,  25,   1,   0, 234,   1,  29,\n",
              "        51,  72, 235,   1,  19,   5,   1,  17, 236, 237,  72, 238,   3,\n",
              "       239,   4,  11,  71, 240,   4, 241, 242, 243, 244, 245,   4, 246,\n",
              "        63, 247,   4,  31,  19,  28,   1,  21,   0,   6, 248,  66,  37,\n",
              "       249, 250,  67,  11,  47,  68,  69,   5,  27, 251,   8,  42, 252,\n",
              "       253,  39, 254,  39, 255,   5,  39, 256,   9,  30,  18, 257,   1,\n",
              "       258,   9,   3,   0,  27,  73,  50,   1,  15,  57,  58,  59, 261,\n",
              "        10,   3,   6,  33, 262, 263, 264,  34,   1, 265, 266,   1,  54,\n",
              "        12,  53,   5, 267,  73, 268,   3, 269,   6, 270, 271, 272,  34],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
      ],
      "metadata": {
        "id": "6mQg1ntXg2sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIDFbKt-cV4W",
        "outputId": "5b3158e2-6cd0-4e32-d95a-ed241e6a9e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After pre proccessing, build and train the model respectively."
      ],
      "metadata": {
        "id": "mbnJ57eRUHan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tis0Tm5tdM3L",
        "outputId": "c7d68d61-6d56-477e-a1c0-79541ed89330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 75, 100)           27400     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 274)               27674     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 135474 (529.20 KB)\n",
            "Trainable params: 135474 (529.20 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(RNN(SimpleRNNCell(100)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uBIWHV0lrQ3",
        "outputId": "b61fddab-12ad-4f11-d9b4-4a43d13552f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 75, 100)           27400     \n",
            "                                                                 \n",
            " rnn (RNN)                   (None, 100)               20100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 274)               27674     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75174 (293.65 KB)\n",
            "Trainable params: 75174 (293.65 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=50, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "hVK6ipDNemqu",
        "outputId": "b560a8d5-d4aa-46e1-bfce-179622b4ed4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 75), found shape=(None, 73)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e9387141c4b2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 75), found shape=(None, 73)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here we analyse our build model and accurecy."
      ],
      "metadata": {
        "id": "inEFO9ZnUbwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "input_text = \"Malik’s wife\"\n",
        "predict_next_words = 4\n",
        "\n",
        "\n",
        "for _ in range(predict_next_words):\n",
        "    token_list = mytokenizer.texts_to_sequences([input_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "    output_word = \"\"\n",
        "    for word, index in mytokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    input_text += \" \" + output_word\n",
        "\n",
        "print(input_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnqZ9aBvhLGf",
        "outputId": "a7e76f68-0542-4084-acb5-1bd75de239e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Malik’s wife said 147 minister district\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xEmOJPa9A0ZJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}